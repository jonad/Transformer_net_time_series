{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_dj.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonad/Transformer_net_time_series/blob/master/transformer_dj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPC8cdXWWcBb",
        "colab_type": "text"
      },
      "source": [
        "## Transformer network for financial trading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUKkJA-XWmp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzPNcOcXoy4F",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1kCuwH7rOpdqjF9ZPACwIOaW5TpxFQ0cy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SVRtLhhpUIs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XvOhQRW5Gyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math, random\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import pandas as pd\n",
        "from scipy import signal \n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_OfSq4H5ai6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import floor\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class StockDataSet(Dataset):\n",
        "\n",
        " def __init__(self, lookback=60, q=19, start_date=\"2012-01-01\", end_date=\"2019-08-31\"):\n",
        "  data = yf.download(\"^GSPC\", start=start_date, end=end_date, group_by=\"ticker\")\n",
        "  data['Close+1'] = data.Close.shift(1)\n",
        "  data['Return'] = (data['Close+1'] - data.Close) / data['Close+1']\n",
        "  data['Trend'] = (data.Close.shift(-q) - data.Close) / data.Close\n",
        "  data['Target'] = np.where(data['Trend'] > 0, 1, 0)\n",
        "  data = data.dropna()\n",
        "  trend = data[\"Trend\"].values\n",
        "  trend = np.reshape(trend, (len(trend), 1))\n",
        "  sc = MinMaxScaler()\n",
        "  self.inputs = sc.fit_transform(trend)\n",
        "  target = data[\"Target\"].values\n",
        "  self.labels = np.reshape(target, (len(target), 1))\n",
        "  self.lookback = lookback\n",
        "  #assert len(self.inputs) == len(self.labels)\n",
        "\n",
        " def __getitem__(self, index):\n",
        "  x = self.inputs[index: (index + self.lookback)]\n",
        "  y = self.labels[index + self.lookback]\n",
        "  return torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
        "\n",
        " def __len__(self):\n",
        "  return len(self.inputs) - self.lookback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4nuLcni57lw",
        "colab_type": "code",
        "outputId": "785720da-0dca-4eaf-cbd8-afe69fcca96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/53/0e/40387099824c98be22cd7e33a620e9d38b61998b031f0b33f0b9959717d2/yfinance-0.1.45.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.16.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.9.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.24->yfinance) (1.12.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.45-cp36-none-any.whl size=14652 sha256=fd8db50b96671e3465d438762a9be21d01bc858a9fe58b5023560d747dc75bb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/d1/df/aa9a7744a4ac353cc9a1f2c3aaea7c1f457fc49de4286f2d88\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krK3YgCHU_gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kO5CN-65lmV",
        "colab_type": "code",
        "outputId": "8fe7f4e0-9393-4af4-c4e9-cbd0592db8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = StockDataSet()\n",
        "training_size = floor(0.9 * len(dataset))\n",
        "validation_size = len(dataset) - training_size\n",
        "train_dataset, val_dataset = random_split(dataset, [training_size, validation_size])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PghWLdmjOgCJ",
        "colab_type": "code",
        "outputId": "a4c671de-a657-4615-9525-0ce77de36687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i, (images, labels) in enumerate(train_loader):\n",
        "    print(images.shape)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 60, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8jmXpPX-cN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, sequence_length, output_size, batch_size, d_model=1, nhead=1, num_encoders_layers=6):\n",
        "    super(Transformer, self).__init__()\n",
        "    \n",
        "    self.output_size = output_size\n",
        "    self.batch_size = batch_size\n",
        "    self.sequence_length = sequence_length\n",
        "    self.encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=1)\n",
        "    self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_encoders_layers)\n",
        "    self.fc = nn.Linear(self.sequence_length, output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, src):\n",
        "    out = self.transformer_encoder(src)\n",
        "    out= out.view(self.batch_size, -1)\n",
        "    out = self.fc(out)\n",
        "    sig_out = self.sigmoid(out)\n",
        "    return sig_out\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COjcdfLfTmQN",
        "colab_type": "code",
        "outputId": "3be7d7ec-8ebf-4002-b748-e79f8566b302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sequenze_length = 60\n",
        "output_size = 1\n",
        "batch_size = 3\n",
        "d_model = 1\n",
        "nhead = 1\n",
        "num_encoders_layers = 10\n",
        "\n",
        "dataset = StockDataSet()\n",
        "training_size = floor(0.9 * len(dataset))\n",
        "validation_size = len(dataset) - training_size\n",
        "train_dataset, val_dataset = random_split(dataset, [training_size, validation_size])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "net = Transformer(sequenze_length, output_size, batch_size, d_model, nhead, num_encoders_layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMATXpLN8ciW",
        "colab_type": "code",
        "outputId": "a20e5b98-3f97-4d78-9c34-e397e90e19d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### training\n",
        "lr = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "epochs = 3\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net.to(device)\n",
        "counter = 0\n",
        "for e in range(epochs):\n",
        "  net.train()\n",
        "  \n",
        "  for inputs, labels in train_loader:\n",
        "    if len(inputs) != batch_size:\n",
        "          continue\n",
        "    counter += 1\n",
        "    net.zero_grad()\n",
        "    \n",
        "    # get the output\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "        \n",
        "    output = net(inputs)\n",
        "    \n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "  #get the validation loss\n",
        "  val_losses = []\n",
        "  val_acc = []\n",
        "  net.eval()\n",
        "  for inputs, labels in val_loader:\n",
        "    if len(inputs) != batch_size:\n",
        "          continue\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    output = net(inputs)\n",
        "    val_loss = criterion(output.squeeze(), labels.float())\n",
        "    \n",
        "    output = (output > 0.5).float()\n",
        "    correct = (output.cpu().numpy().flatten() == \\\n",
        "                   labels.cpu().numpy().flatten()).sum() / output.shape[0]\n",
        "    val_losses.append(val_loss.item())\n",
        "    val_acc.append(correct)\n",
        "          \n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "          \"Step: {}...\".format(counter),\n",
        "          \"Loss: {:.6f}...\".format(loss.item()),\n",
        "          \"Val Loss: {:.6f}\".format(np.mean(val_losses)),\n",
        "          \"Val Accuracy: {:.6f}\".format(np.mean(val_acc)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.934945 Val Accuracy: 0.333333\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.934945 Val Accuracy: 0.333333\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.836780 Val Accuracy: 0.444444\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.861321 Val Accuracy: 0.416667\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.817147 Val Accuracy: 0.466667\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.787698 Val Accuracy: 0.500000\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.808733 Val Accuracy: 0.476190\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.787698 Val Accuracy: 0.500000\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.771337 Val Accuracy: 0.518519\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.787698 Val Accuracy: 0.500000\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.774312 Val Accuracy: 0.515152\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.738615 Val Accuracy: 0.555556\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.776371 Val Accuracy: 0.512821\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.766662 Val Accuracy: 0.523810\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.758248 Val Accuracy: 0.533333\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.750886 Val Accuracy: 0.541667\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.761713 Val Accuracy: 0.529412\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.787698 Val Accuracy: 0.500000\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.779948 Val Accuracy: 0.508772\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.772973 Val Accuracy: 0.516667\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.766662 Val Accuracy: 0.523810\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.760925 Val Accuracy: 0.530303\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.742883 Val Accuracy: 0.550725\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.738615 Val Accuracy: 0.555556\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.734689 Val Accuracy: 0.560000\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.719737 Val Accuracy: 0.576923\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.716801 Val Accuracy: 0.580247\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.735109 Val Accuracy: 0.559524\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.731845 Val Accuracy: 0.563218\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.728799 Val Accuracy: 0.566667\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.716449 Val Accuracy: 0.580645\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.714074 Val Accuracy: 0.583333\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.711843 Val Accuracy: 0.585859\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.701082 Val Accuracy: 0.598039\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.716178 Val Accuracy: 0.580952\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.705894 Val Accuracy: 0.592593\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.712084 Val Accuracy: 0.585586\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.710199 Val Accuracy: 0.587719\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.708411 Val Accuracy: 0.589744\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.714074 Val Accuracy: 0.583333\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.712278 Val Accuracy: 0.585366\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.703556 Val Accuracy: 0.595238\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.702089 Val Accuracy: 0.596899\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.700688 Val Accuracy: 0.598485\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.692805 Val Accuracy: 0.607407\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.691667 Val Accuracy: 0.608696\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.696843 Val Accuracy: 0.602837\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.689533 Val Accuracy: 0.611111\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.688531 Val Accuracy: 0.612245\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.681680 Val Accuracy: 0.620000\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.680871 Val Accuracy: 0.620915\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.674431 Val Accuracy: 0.628205\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.668233 Val Accuracy: 0.635220\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.673172 Val Accuracy: 0.629630\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.667223 Val Accuracy: 0.636364\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.661486 Val Accuracy: 0.642857\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.671450 Val Accuracy: 0.631579\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.670915 Val Accuracy: 0.632184\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.670399 Val Accuracy: 0.632768\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.669900 Val Accuracy: 0.633333\n",
            "Epoch: 1/3... Step: 554... Loss: 0.345075... Val Loss: 0.674245 Val Accuracy: 0.628415\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.922344 Val Accuracy: 0.333333\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.922344 Val Accuracy: 0.333333\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.827956 Val Accuracy: 0.444444\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.851553 Val Accuracy: 0.416667\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.809079 Val Accuracy: 0.466667\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.780762 Val Accuracy: 0.500000\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.800988 Val Accuracy: 0.476190\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.780762 Val Accuracy: 0.500000\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.765031 Val Accuracy: 0.518519\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.780762 Val Accuracy: 0.500000\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.767891 Val Accuracy: 0.515152\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.733569 Val Accuracy: 0.555556\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.769872 Val Accuracy: 0.512821\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.760536 Val Accuracy: 0.523810\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.752446 Val Accuracy: 0.533333\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.745367 Val Accuracy: 0.541667\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.755777 Val Accuracy: 0.529412\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.780762 Val Accuracy: 0.500000\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.773311 Val Accuracy: 0.508772\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.766604 Val Accuracy: 0.516667\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.760536 Val Accuracy: 0.523810\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.755020 Val Accuracy: 0.530303\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.737672 Val Accuracy: 0.550725\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.733569 Val Accuracy: 0.555556\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.729793 Val Accuracy: 0.560000\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.715417 Val Accuracy: 0.576923\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.712594 Val Accuracy: 0.580247\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.730198 Val Accuracy: 0.559524\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.727059 Val Accuracy: 0.563218\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.724130 Val Accuracy: 0.566667\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.712255 Val Accuracy: 0.580645\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.709972 Val Accuracy: 0.583333\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.707827 Val Accuracy: 0.585859\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.697479 Val Accuracy: 0.598039\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.711994 Val Accuracy: 0.580952\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.702106 Val Accuracy: 0.592593\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.708058 Val Accuracy: 0.585586\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.706246 Val Accuracy: 0.587719\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.704526 Val Accuracy: 0.589744\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.709972 Val Accuracy: 0.583333\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.708245 Val Accuracy: 0.585366\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.699859 Val Accuracy: 0.595238\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.698448 Val Accuracy: 0.596899\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.697101 Val Accuracy: 0.598485\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.689521 Val Accuracy: 0.607407\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.688427 Val Accuracy: 0.608696\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.693404 Val Accuracy: 0.602837\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.686375 Val Accuracy: 0.611111\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.685412 Val Accuracy: 0.612245\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.678824 Val Accuracy: 0.620000\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.678047 Val Accuracy: 0.620915\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.671854 Val Accuracy: 0.628205\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.665895 Val Accuracy: 0.635220\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.670644 Val Accuracy: 0.629630\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.664923 Val Accuracy: 0.636364\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.659407 Val Accuracy: 0.642857\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.668988 Val Accuracy: 0.631579\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.668474 Val Accuracy: 0.632184\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.667977 Val Accuracy: 0.632768\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.667497 Val Accuracy: 0.633333\n",
            "Epoch: 2/3... Step: 1108... Loss: 0.923038... Val Loss: 0.671675 Val Accuracy: 0.628415\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.892464 Val Accuracy: 0.333333\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.892464 Val Accuracy: 0.333333\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.807343 Val Accuracy: 0.444444\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.828623 Val Accuracy: 0.416667\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.790318 Val Accuracy: 0.466667\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.764782 Val Accuracy: 0.500000\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.783022 Val Accuracy: 0.476190\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.764782 Val Accuracy: 0.500000\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.750595 Val Accuracy: 0.518519\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.764782 Val Accuracy: 0.500000\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.753175 Val Accuracy: 0.515152\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.722222 Val Accuracy: 0.555556\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.754960 Val Accuracy: 0.512821\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.746542 Val Accuracy: 0.523810\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.739246 Val Accuracy: 0.533333\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.732862 Val Accuracy: 0.541667\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.742250 Val Accuracy: 0.529412\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.764782 Val Accuracy: 0.500000\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.758062 Val Accuracy: 0.508772\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.752014 Val Accuracy: 0.516667\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.746542 Val Accuracy: 0.523810\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.741567 Val Accuracy: 0.530303\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.725922 Val Accuracy: 0.550725\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.722222 Val Accuracy: 0.555556\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.718817 Val Accuracy: 0.560000\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.705852 Val Accuracy: 0.576923\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.703306 Val Accuracy: 0.580247\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.719182 Val Accuracy: 0.559524\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.716351 Val Accuracy: 0.563218\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.713709 Val Accuracy: 0.566667\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.703001 Val Accuracy: 0.580645\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.700941 Val Accuracy: 0.583333\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.699007 Val Accuracy: 0.585859\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.689675 Val Accuracy: 0.598039\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.702765 Val Accuracy: 0.580952\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.693848 Val Accuracy: 0.592593\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.699216 Val Accuracy: 0.585586\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.697581 Val Accuracy: 0.587719\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.696030 Val Accuracy: 0.589744\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.700941 Val Accuracy: 0.583333\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.699384 Val Accuracy: 0.585366\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.691821 Val Accuracy: 0.595238\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.690549 Val Accuracy: 0.596899\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.689334 Val Accuracy: 0.598485\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.682498 Val Accuracy: 0.607407\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.681511 Val Accuracy: 0.608696\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.686000 Val Accuracy: 0.602837\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.679661 Val Accuracy: 0.611111\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.678792 Val Accuracy: 0.612245\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.672851 Val Accuracy: 0.620000\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.672150 Val Accuracy: 0.620915\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.666565 Val Accuracy: 0.628205\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.661191 Val Accuracy: 0.635220\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.665474 Val Accuracy: 0.629630\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.660315 Val Accuracy: 0.636364\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.655341 Val Accuracy: 0.642857\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.663981 Val Accuracy: 0.631579\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.663517 Val Accuracy: 0.632184\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.663070 Val Accuracy: 0.632768\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.662637 Val Accuracy: 0.633333\n",
            "Epoch: 3/3... Step: 1662... Loss: 0.892196... Val Loss: 0.666404 Val Accuracy: 0.628415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIolMtRkOLtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}